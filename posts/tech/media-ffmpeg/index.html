<!doctype html>
<html lang="zh-cn">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>FFmpeg软件学习 - 理想奈的博客</title><link rel="apple-touch-icon" href="/images/favicons/apple-touch-icon.png" sizes="180x180">
<link rel="icon" href="/images/favicons/favicon-32x32.png" sizes="32x32" type="image/png">
<link rel="icon" href="/images/favicons/favicon-16x16.png" sizes="16x16" type="image/png">
<link rel="manifest" href="/images/favicons/manifest.json">
<link rel="icon" href="/images/favicons/favicon.ico">
<meta name="keywords" content="" />
<meta name="description" content="" /><meta itemprop="name" content="FFmpeg软件学习">
<meta itemprop="description" content=""><meta itemprop="datePublished" content="2024-12-05T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2024-12-05T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="15680">
<meta itemprop="keywords" content=",,," /><meta property="og:title" content="FFmpeg软件学习" />
<meta property="og:description" content="" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/tech/media-ffmpeg/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-12-05T00:00:00&#43;00:00" />
<meta property="article:modified_time" content="2024-12-05T00:00:00&#43;00:00" /><meta property="og:site_name" content="理想奈的博客" />


<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="FFmpeg软件学习"/>
<meta name="twitter:description" content=""/>
<meta data-name="palette" content="blue"><link rel=stylesheet href="/css/bundle.min.d63d5781d5b3b2441c3e0c8ba081eb171c0ae292f799670fe6d38f68e3a2816d.css" integrity="sha256-1j1XgdWzskQcPgyLoIHrFxwK4pL3mWcP5tOPaOOigW0=" crossorigin="anonymous"><script src="/js/bundle.min.1c471eeba442e80350b91324d765b69b27af83f0de35d552aa2a410bac6ee793.js" integrity="sha256-HEce66RC6ANQuRMk12W2myevg/DeNdVSqipBC6xu55M=" crossorigin="anonymous"></script>
<script type="text/javascript">
	document.addEventListener("DOMContentLoaded", function() {
  renderMathInElement(document.body, {
    delimiters: [
      {left: "$$", right: "$$", display: true},
      {left: "$", right: "$", display: false}
    ],
    macros: {
      "\\ge": "\\geqslant",
      "\\le": "\\leqslant",
      "\\geq": "\\geqslant",
      "\\leq": "\\leqslant"
	}
  });
}); 
</script>
<meta property="og:type" content="index"/>
<meta property="og:title" content="Unzybaryl`s Sekai" />
<meta property="og:image" content="https://eustia.me/images/profile1.jpg" />
<meta property="og:url" content="https://eustia.me/" />





<script type="text/javascript" src="/js/Valine.min.js"></script>
<script type="text/javascript" src="/js/cave-draw.min.js"></script>
<link rel="stylesheet" type="text/css" href="/js/katex.min.css">
<script type="text/javascript" src="/js/katex.min.js"></script>
<script type="text/javascript" src="/js/auto-render.min.js"></script>
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link rel="stylesheet" type="text/css" href="/js/font.css">

</head><body><header><nav class="navbar navbar-expand-xl fixed-top">
  <div class="container">
    <a class="navbar-brand" href="/">
      
      
      さぁ、君、取りたまえ
      
    </a>
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav me-1 mb-2 mb-lg-0"><form class="search-bar d-flex ms-1" action="/search">
  <div class="input-group input-group-sm">
    <button class="btn btn-search disabled position-absolute left-0" type="submit"><i class="fas fa-fw fa-search"></i></button>
    <input class="form-control rounded-pill" id="searchQuery" name="q" type="search" aria-label="Search">
  </div>
</form></ul><ul class="navbar-nav me-1 mb-2 mb-lg-0 me-1 ms-auto"><li class="nav-item">
          <a class="nav-link" href="/archives">
            <i class="fas fa-fw fa-file-archive"></i>归档
          </a>
        </li><li class="nav-item">
          <a class="nav-link" href="/about/">
            <i class="fas fa-fw fa-info-circle"></i>关于
          </a>
        </li><li class="nav-item">
          <a class="nav-link" href="/bin/">
            <i class="fas fa-fw fa-bookmark"></i>废案
          </a>
        </li><li class="nav-item">
  <a class="nav-link" data-bs-toggle="offcanvas" href="#offcanvasSettings" role="button"
    aria-controls="offcanvasSettings">
    <i class="fas fa-fw fa-sliders-h"></i> 设置
  </a>
</li>

<div class="offcanvas offcanvas-end surface h-100" tabindex="-1" id="offcanvasSettings"
  aria-labelledby="offcanvasSettingsLabel">
  <div class="offcanvas-header">
    <h5 class="offcanvas-title" w id="offcanvasSettingsLabel"><i class="fas fa-fw fa-sliders-h"></i> 设置</h5>
    <a role="button" data-bs-dismiss="offcanvas" aria-label="Close">
      <span class="fas fa-2x fa-fw fa-times"></span>
    </a>
  </div>
  <div class="offcanvas-body"><section class="setting">
  <form class="row">
    <div class="col-auto">
      <label><i class="fas fa-fw fa-adjust"></i> 模式</label>
    </div>
    <div class="col-auto ms-auto">
      <div class="form-check form-switch">
        <input class="form-check-input" type="checkbox" id="modeSwitcher">
      </div>
    </div>
  </form>
</section>
<section class="setting">
  <form class="font-size-switcher-form row">
    <div class="col-auto">
      <label for="fontSize" class="form-label"><i class="fas fa-fw fa-font"></i> 字体大小</label>
    </div>
    <div class="col-auto ms-auto">
      <input type="range" class="form-range" min="-2" max="2" id="fontSize">
    </div>
  </form>
</section>

</div>
</div></ul>
    </div>
  </div>
</nav>
</header>
<main role="main" class="container">
      <div class="row content">
<div class="col-lg-8">
  <div class="container"><nav class="row" aria-label="breadcrumb">
  <ol class="breadcrumb surface"><li class="breadcrumb-item"><a href="/">主页</a></li><li class="breadcrumb-item"><a href="/posts/">文章</a></li><li class="breadcrumb-item"><a href="/posts/tech/">Tech</a></li><li class="breadcrumb-item active">FFmpeg软件学习</li></ol>
</nav><article class="post row surface"><div class="post-panel-wrapper">
  <div class="post-panel d-flex flex-column">
    <a id="sidebarToggler" class="action d-none d-lg-block" role="button">
  <i class="fas fa-fw fa-expand-alt fa-rotate-45"></i>
</a>
  
    

    
    <a class="action" data-bs-container="body" data-bs-toggle="popover" data-bs-html="true" data-bs-placement="bottom"
  data-bs-trigger="focus" tabindex="0"
  data-bs-content="&lt;a target=&#34;_blank&#34; rel=&#34;license&#34; href=&#34;https://creativecommons.org/licenses/by-nc-nd/4.0/deed.zh&#34;&gt;CC BY-NC-ND 4.0 &lt;i class=&#34;fab fa-fw fa-creative-commons&#34;&gt;&lt;/i&gt;&lt;i class=&#34;fab fa-fw fa-creative-commons-by&#34;&gt;&lt;/i&gt;&lt;i class=&#34;fab fa-fw fa-creative-commons-nc&#34;&gt;&lt;/i&gt;&lt;i class=&#34;fab fa-fw fa-creative-commons-nd&#34;&gt;&lt;/i&gt;&lt;/a&gt;
">
  <i class="fas fa-fw fa-copyright"></i>
</a>
    <a id="btnTOC" class="fas fa-fw fa-list-alt" data-bs-toggle="offcanvas" href="#offcanvasTOC" aria-controls="offcanvasTOC" role="button">
</a>
  </div>
</div>
<h1 class="post-title my-3">FFmpeg软件学习
</h1><div class="post-meta mb-3">
  <span class="post-date me-2">
    <i class="fas fa-fw fa-calendar-alt"></i>2024-12-05
  </span>
  <span class="post-reading-time me-2">
    <i class="fas fa-fw fa-coffee"></i>32 分钟阅读
  </span>
<a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/" class="post-taxonomy">#计算机</a><a href="/series/%E5%AA%92%E4%BD%93%E5%BC%80%E5%8F%91/" class="post-taxonomy">#媒体开发</a></div>



                
                <div class="addthis_inline_share_toolbox"></div>
            <div class="offcanvas offcanvas-end surface" tabindex="-1" id="offcanvasTOC" aria-labelledby="offcanvasTOCLabel">
  <div class="offcanvas-header">
    <h5 class="offcanvas-title" id="offcanvasTOCLabel">目录</h5>
    <a role="button" data-bs-dismiss="offcanvas" aria-label="Close">
      <span class="fas fa-2x fa-fw fa-times"></span>
    </a>
  </div>
  <div class="offcanvas-body">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#安装">安装</a></li>
    <li><a href="#官方文档">官方文档</a>
      <ul>
        <li><a href="#1-概要">1. 概要</a></li>
        <li><a href="#2-说明">2. 说明</a></li>
        <li><a href="#3-详细描述">3. 详细描述</a></li>
        <li><a href="#4-stream-selection流选择">4 Stream selection（流选择）</a></li>
        <li><a href="#5-options选项">5 Options（选项）</a></li>
      </ul>
    </li>
    <li><a href="#使用">使用</a>
      <ul>
        <li><a href="#教程">教程</a></li>
        <li><a href="#官方示例">官方示例</a></li>
      </ul>
    </li>
    <li><a href="#场景">场景</a>
      <ul>
        <li><a href="#推流">推流</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div><div class="post-content mb-3" ><h2 id="安装">安装</h2>
<p>源码安装：</p>
<p><a href="https://blog.csdn.net/qq_41004932/article/details/117049095">https://blog.csdn.net/qq_41004932/article/details/117049095</a></p>
<p>这篇文章先看“解决ffplay没有的问题”那节。</p>
<p>当然也可以一步到位直接<code>sudo apt-get ffmpeg</code>。</p>
<h2 id="官方文档">官方文档</h2>
<p><a href="https://ffmpeg.org/ffmpeg.html">https://ffmpeg.org/ffmpeg.html</a></p>
<p>目前来说没必要全部阅读，有疑问去查阅即可。</p>
<h3 id="1-概要">1. 概要</h3>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg [global_options] {[input_file_options] -i INPUT_FILE} ... {[output_file_options] OUTPUT_FILE} ...}
</code></pre></div><h3 id="2-说明">2. 说明</h3>
<p><code>ffmpeg</code>从输入“文件”（其可以是常规文件，管道，网络流，录制装置等），由指定任意数量的读取<code>-i</code>选项，<strong>并写入到任意数量的输出“文件”</strong>，只需指定一个输出的文件名。任何一个命令行中不能被解释为选项的内容都被认为是一个输出文件名。每个输入或输出文件可以在原则上，包含任意数量的不同类型（视频/音频/字幕/附件/数据）的流。输出文件中允许流的数量和类型是由输出格式容器限制决定的。输入流和输出流直接的映射可以自动完成也可以用<code>-map</code>选项给定（见流选择章节)。</p>
<p>引用输入文件的选项时，则必须使用他们的<strong>索引（从0开始）</strong>。例如：第一输入文件是0 ，第二个是1等。类似地，一个文件中的流也通过其索引指定。例如2:3指的是在第三个输入文件中的第四数据流。参见流章节。</p>
<p>作为一般规则，选项作用于下一个指定的文件。因此，命令的顺序是重要，你可以在命令行上多次相同的选项。每次选项的出现都将作用于下一个输入或输出文件。这条规则若有例外将会提前声明（例如冗余级别）。不要混合输入和输出文件。首先指定所有输入文件，那么所有的输出文件。也不要混用属于不同的文件的选项。<strong>所有选项仅适用于下一个输入或输出文件</strong>，之后选项将被重置。</p>
<p>例：</p>
<ul>
<li>
<p>设置输出文件以64千比特/秒的视频比特率</p>
<p><code>ffmpeg -i input.avi -b：V 64K -bufsize 64K output.avi</code></p>
</li>
<li>
<p>要强制输出文件为24 fps的帧速率</p>
<p><code>ffmpeg -i input.avi -r 24 output.avi</code></p>
</li>
<li>
<p>要强制输入文件的帧频（仅对原始格式有效），以1 FPS读入文件，以每秒24帧的帧速率输出</p>
<p><code>ffmpeg -r 1 -i input.m2v -r 24 output.avi</code></p>
</li>
</ul>
<h3 id="3-详细描述">3. 详细描述</h3>
<p><code>ffmpeg</code> builds a transcoding pipeline（转码管道） out of the components listed below. The program’s operation then consists of input data chunks（数据块） flowing from the sources down the pipes towards the sinks, while being transformed by the components they encounter along the way.</p>
<p>The following kinds of components are available:</p>
<ul>
<li>
<p>Demuxers (short for &ldquo;demultiplexers&rdquo;) （多路分流器）read an input source in order to extract</p>
<ul>
<li>global properties such as metadata or chapters;</li>
<li>list of input elementary streams and their properties</li>
</ul>
<p>One demuxer instance is created for each -i option, and sends encoded <em>packets</em> to <em>decoders</em> or <em>muxers</em>.</p>
<p>In other literature, demuxers are sometimes called <em>splitters</em>（分流器）, because their main function is splitting a file into elementary streams (though some files only contain one elementary stream).</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln"> 1</span>┌──────────┬───────────────────────┐
<span class="ln"> 2</span>│ demuxer  │                       │ packets for stream 0
<span class="ln"> 3</span>╞══════════╡ elementary stream 0   ├──────────────────────⮞
<span class="ln"> 4</span>│          │                       │
<span class="ln"> 5</span>│  global  ├───────────────────────┤
<span class="ln"> 6</span>│properties│                       │ packets for stream 1
<span class="ln"> 7</span>│   and    │ elementary stream 1   ├──────────────────────⮞
<span class="ln"> 8</span>│ metadata │                       │
<span class="ln"> 9</span>│          ├───────────────────────┤
<span class="ln">10</span>│          │                       │
<span class="ln">11</span>│          │     ...........       │
<span class="ln">12</span>│          │                       │
<span class="ln">13</span>│          ├───────────────────────┤
<span class="ln">14</span>│          │                       │ packets for stream N
<span class="ln">15</span>│          │ elementary stream N   ├──────────────────────⮞
<span class="ln">16</span>│          │                       │
<span class="ln">17</span>└──────────┴───────────────────────┘
<span class="ln">18</span>     ⯅
<span class="ln">19</span>     │
<span class="ln">20</span>     │ read from file, network stream,
<span class="ln">21</span>     │     grabbing device, etc.
<span class="ln">22</span>     │
</code></pre></div></li>
<li>
<p><em>Decoders</em>（解码器） receive encoded (compressed) <em>packets</em> for an audio, video, or subtitle elementary stream, and decode them into raw <em>frames</em> (arrays of pixels for video, PCM for audio). A decoder is typically associated with (and receives its input from) an elementary stream in a <em>demuxer</em>, but sometimes may also exist on its own (see Loopback decoders).</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>          ┌─────────┐
<span class="ln">2</span> packets  │         │ raw frames
<span class="ln">3</span>─────────⮞│ decoder ├────────────⮞
<span class="ln">4</span>          │         │
<span class="ln">5</span>          └─────────┘
</code></pre></div></li>
<li>
<p><em>Filtergraphs</em>（滤镜图） process and transform raw audio or video <em>frames</em>. A filtergraph consists of one or more individual <em>filters</em> linked into a graph. Filtergraphs come in two flavors（风格） - <em>simple</em> and <em>complex</em>, configured with the -filter and -filter_complex options, respectively.</p>
<p>A simple filtergraph（简单滤镜图）is associated with an <em>output elementary stream</em>; it receives the input to be filtered from a <em>decoder</em> and sends filtered output to that output stream’s <em>encoder</em>.</p>
<p>A simple video filtergraph that performs deinterlacing（去隔行处理） (using the <code>yadif</code> deinterlacer) followed by resizing（调整大小） (using the <code>scale</code> filter) can look like this:</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>             ┌────────────────────────┐
<span class="ln">2</span>             │  simple filtergraph    │
<span class="ln">3</span> frames from ╞════════════════════════╡ frames for
<span class="ln">4</span> a decoder   │  ┌───────┐  ┌───────┐  │ an encoder
<span class="ln">5</span>────────────⮞├─⮞│ yadif ├─⮞│ scale ├─⮞│────────────⮞
<span class="ln">6</span>             │  └───────┘  └───────┘  │
<span class="ln">7</span>             └────────────────────────┘
</code></pre></div><p>A complex filtergraph（复杂滤镜图） is standalone and not associated with any specific stream. It may have multiple (or zero) inputs, potentially of different types (audio or video), each of which receiving data either from a decoder or another complex filtergraph’s output. It also has one or more outputs that feed either an encoder or another complex filtergraph’s input.</p>
<p>The following example diagram represents a complex filtergraph with 3 inputs and 2 outputs (all video):</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln"> 1</span>          ┌─────────────────────────────────────────────────┐
<span class="ln"> 2</span>          │               complex filtergraph               │
<span class="ln"> 3</span>          ╞═════════════════════════════════════════════════╡
<span class="ln"> 4</span> frames   ├───────┐  ┌─────────┐      ┌─────────┐  ┌────────┤ frames
<span class="ln"> 5</span>─────────⮞│input 0├─⮞│ overlay ├─────⮞│ overlay ├─⮞│output 0├────────⮞
<span class="ln"> 6</span>          ├───────┘  │         │      │         │  └────────┤
<span class="ln"> 7</span> frames   ├───────┐╭⮞│         │    ╭⮞│         │           │
<span class="ln"> 8</span>─────────⮞│input 1├╯ └─────────┘    │ └─────────┘           │
<span class="ln"> 9</span>          ├───────┘                 │                       │
<span class="ln">10</span> frames   ├───────┐ ┌─────┐ ┌─────┬─╯              ┌────────┤ frames
<span class="ln">11</span>─────────⮞│input 2├⮞│scale├⮞│split├───────────────⮞│output 1├────────⮞
<span class="ln">12</span>          ├───────┘ └─────┘ └─────┘                └────────┤
<span class="ln">13</span>          └─────────────────────────────────────────────────┘
</code></pre></div><p>Frames from second input are overlaid（覆盖） over those from the first. Frames from the third input are rescaled（重新缩放）, then the duplicated into two identical streams. One of them is overlaid over the combined first two inputs, with the result exposed as（显示） the filtergraph’s first output. The other duplicate ends up being the filtergraph’s second output.</p>
</li>
<li>
<p><em>ncoders</em> receive raw audio, video, or subtitle（字幕） <em>frames</em> and encode them into encoded <em>packets</em>. The encoding (compression) process is typically <em>lossy</em>（有损的） - it degrades（降级） stream quality to make the output smaller; some encoders are <em>lossless</em>, but at the cost of much higher output size. A video or audio encoder receives its input from some filtergraph’s output, subtitle encoders receive input from a decoder (since subtitle filtering is not supported yet). Every encoder is associated with some muxer’s <em>output elementary stream</em> and sends its output to that muxer.</p>
<p>A schematic（原理的） representation of an encoder looks like this:</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>             ┌─────────┐
<span class="ln">2</span> raw frames  │         │ packets
<span class="ln">3</span>────────────⮞│ encoder ├─────────⮞
<span class="ln">4</span>             │         │
<span class="ln">5</span>             └─────────┘
</code></pre></div></li>
<li>
<p><em>Muxers</em> (short for &ldquo;multiplexers&rdquo;) receive encoded <em>packets</em> for their elementary streams from encoders (the <em>transcoding</em>（转码） path) or directly from demuxers (the <em>streamcopy</em>（流式拷贝） path), interleave（交错） them (when there is more than one elementary stream), and write the resulting bytes into the output file (or pipe, network stream, etc.).</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln"> 1</span>                       ┌──────────────────────┬───────────┐
<span class="ln"> 2</span> packets for stream 0  │                      │   muxer   │
<span class="ln"> 3</span>──────────────────────⮞│  elementary stream 0 ╞═══════════╡
<span class="ln"> 4</span>                       │                      │           │
<span class="ln"> 5</span>                       ├──────────────────────┤  global   │
<span class="ln"> 6</span> packets for stream 1  │                      │properties │
<span class="ln"> 7</span>──────────────────────⮞│  elementary stream 1 │   and     │
<span class="ln"> 8</span>                       │                      │ metadata  │
<span class="ln"> 9</span>                       ├──────────────────────┤           │
<span class="ln">10</span>                       │                      │           │
<span class="ln">11</span>                       │     ...........      │           │
<span class="ln">12</span>                       │                      │           │
<span class="ln">13</span>                       ├──────────────────────┤           │
<span class="ln">14</span> packets for stream N  │                      │           │
<span class="ln">15</span>──────────────────────⮞│  elementary stream N │           │
<span class="ln">16</span>                       │                      │           │
<span class="ln">17</span>                       └──────────────────────┴─────┬─────┘
<span class="ln">18</span>                                                    │
<span class="ln">19</span>                     write to file, network stream, │
<span class="ln">20</span>                         grabbing device, etc.      │
<span class="ln">21</span>                                                    │
<span class="ln">22</span>                                                    ▼
</code></pre></div></li>
</ul>
<h4 id="31-streamcopy">3.1 Streamcopy</h4>
<p>The simplest pipeline in <code>ffmpeg</code> is single-stream <em>streamcopy</em>（流式拷贝）, that is copying one <em>input elementary stream</em>’s packets without decoding, filtering, or encoding them. As an example, consider an input file called INPUT.mkv with 3 elementary streams, from which we take the second and write it to file OUTPUT.mp4.</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln"> 1</span>┌──────────┬─────────────────────┐
<span class="ln"> 2</span>│ demuxer  │                     │ unused
<span class="ln"> 3</span>╞══════════╡ elementary stream 0 ├────────╳
<span class="ln"> 4</span>│          │                     │
<span class="ln"> 5</span>│INPUT.mkv ├─────────────────────┤          ┌──────────────────────┬───────────┐
<span class="ln"> 6</span>│          │                     │ packets  │                      │   muxer   │
<span class="ln"> 7</span>│          │ elementary stream 1 ├─────────⮞│  elementary stream 0 ╞═══════════╡
<span class="ln"> 8</span>│          │                     │          │                      │OUTPUT.mp4 │
<span class="ln"> 9</span>│          ├─────────────────────┤          └──────────────────────┴───────────┘
<span class="ln">10</span>│          │                     │ unused
<span class="ln">11</span>│          │ elementary stream 2 ├────────╳
<span class="ln">12</span>│          │                     │
<span class="ln">13</span>└──────────┴─────────────────────┘
</code></pre></div><p>将INPUT.mkv的第2个流拷贝到 OUTPUT.mp4：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i INPUT.mkv -map 0:1 -c copy OUTPUT.mp4
</code></pre></div><ul>
<li>there is a single input INPUT.mkv;</li>
<li>there are no input options for this input;</li>
<li>there is a single output OUTPUT.mp4;</li>
<li>there are two output options for this output:</li>
<li><code>-map 0:1</code> selects the input stream to be used - from input with index 0 (i.e. the first one) the stream with index 1 (i.e. the second one);</li>
<li><code>-c copy</code> selects the <code>copy</code> encoder, i.e. streamcopy with no decoding or encoding.</li>
</ul>
<p>Streamcopy is useful for changing the elementary stream count, container format, or modifying container-level metadata. Since there is no decoding or encoding, it is very fast and there is no quality loss. However, it might not work in some cases because of a variety of factors (e.g. certain information required by the target container is not available in the source). Applying filters is obviously also impossible, since filters work on decoded frames.</p>
<p>More complex streamcopy scenarios can be constructed - e.g. combining streams from two input files into a single output:</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln"> 1</span>┌──────────┬─────────────────────┐          ┌───────────────────┬───────────┐
<span class="ln"> 2</span>│ demuxer  │                     │ packets  │                   │ muxer 0   │
<span class="ln"> 3</span>╞══════════╡ elementary stream 0 ├─────────⮞│elementary stream 0╞═══════════╡
<span class="ln"> 4</span>│          │                     │          │                   │OUTPUT0.mp4│
<span class="ln"> 5</span>│INPUT.mkv ├─────────────────────┤          └───────────────────┴───────────┘
<span class="ln"> 6</span>│          │                     │ packets  ┌───────────────────┬───────────┐
<span class="ln"> 7</span>│          │ elementary stream 1 ├─────────⮞│                   │ muxer 1   │
<span class="ln"> 8</span>│          │                     │          │elementary stream 0╞═══════════╡
<span class="ln"> 9</span>└──────────┴─────────────────────┘          │                   │OUTPUT1.mp4│
<span class="ln">10</span>                                            └───────────────────┴───────────┘
</code></pre></div><p>将一个输入的两个流分别拷贝到不同的输出：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i INPUT.mkv -map 0:0 -c copy OUTPUT0.mp4 -map 0:1 -c copy OUTPUT1.mp4
</code></pre></div><p>Note how a separate instance of the -c option is needed for every output file even though their values are the same. This is because non-global options (which is most of them) only apply in the context of the file before which they are placed.</p>
<p>These  examples can of course be further generalized into arbitrary remappings of any number of inputs into any number of outputs.</p>
<h4 id="32-trancoding">3.2 Trancoding</h4>
<p><em>Transcoding</em>（串编码） is the process of decoding a stream and then encoding it again. Since encoding tends to be computationally expensive and in most cases degrades the stream quality (i.e. it is <em>lossy</em>), you should only transcode when you need to and perform streamcopy otherwise（否则）. Typical reasons to transcode are:</p>
<ul>
<li>applying filters（加过滤） - e.g. resizing, deinterlacing（反交错）, or overlaying video; resampling or mixing audio;</li>
<li>you want to feed the stream to something that cannot decode the original codec.（交给不能解码的处理器）</li>
</ul>
<p>Note that <code>ffmpeg</code> will transcode all audio, video, and subtitle streams unless you specify -c copy for them.（自动转码，除非copy）</p>
<p>Consider an example pipeline that reads an input file with one audio and one video stream, transcodes the video and copies the audio into a single output file. This can be schematically represented as follows</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln"> 1</span>┌──────────┬─────────────────────┐
<span class="ln"> 2</span>│ demuxer  │                     │       audio packets
<span class="ln"> 3</span>╞══════════╡ stream 0 (audio)    ├─────────────────────────────────────╮
<span class="ln"> 4</span>│          │                     │                                     │
<span class="ln"> 5</span>│INPUT.mkv ├─────────────────────┤ video    ┌─────────┐     raw        │
<span class="ln"> 6</span>│          │                     │ packets  │  video  │ video frames   │
<span class="ln"> 7</span>│          │ stream 1 (video)    ├─────────⮞│ decoder ├──────────────╮ │
<span class="ln"> 8</span>│          │                     │          │         │              │ │
<span class="ln"> 9</span>└──────────┴─────────────────────┘          └─────────┘              │ │
<span class="ln">10</span>                                                                     ▼ ▼
<span class="ln">11</span>                                                                     │ │
<span class="ln">12</span>┌──────────┬─────────────────────┐ video    ┌─────────┐              │ │
<span class="ln">13</span>│ muxer    │                     │ packets  │  video  │              │ │
<span class="ln">14</span>╞══════════╡ stream 0 (video)    │⮜─────────┤ encoder ├──────────────╯ │
<span class="ln">15</span>│          │                     │          │(libx264)│                │
<span class="ln">16</span>│OUTPUT.mp4├─────────────────────┤          └─────────┘                │
<span class="ln">17</span>│          │                     │                                     │
<span class="ln">18</span>│          │ stream 1 (audio)    │⮜────────────────────────────────────╯
<span class="ln">19</span>│          │                     │
<span class="ln">20</span>└──────────┴─────────────────────┘
</code></pre></div><p>输入INPUT.mkv，对音频进行拷贝，对视频进行libx264编码：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i INPUT.mkv -map 0:v -map 0:a -c:v libx264 -c:a copy OUTPUT.mp4
</code></pre></div><p>Note how it uses stream specifiers <code>:v</code> and <code>:a</code> to select input streams and apply different values of the -c option to them</p>
<h4 id="33-filtering">3.3 Filtering</h4>
<p>When transcoding, audio and video streams can be filtered before encoding, with either a <em>simple</em> or <em>complex</em> filtergraph.</p>
<h5 id="331-simple-filtergraphs">3.3.1 Simple filtergraphs</h5>
<p>Simple filtergraphs are those that have exactly one input and output, both of the same type (audio or video). They are configured with the per-stream <code>-filter</code> option (with <code>-vf</code> and <code>-af</code> aliases for <code>-filter:v</code> (video) and <code>-filter:a</code> (audio) respectively). Note that simple filtergraphs are tied to their output stream, so e.g. if you have multiple audio streams, <code>-af</code> will create a separate filtergraph for each one.</p>
<p>Taking the trancoding example from above, adding filtering (and omitting audio, for clarity) makes it look like this:</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln"> 1</span>┌──────────┬───────────────┐
<span class="ln"> 2</span>│ demuxer  │               │          ┌─────────┐
<span class="ln"> 3</span>╞══════════╡ video stream  │ packets  │  video  │ frames
<span class="ln"> 4</span>│INPUT.mkv │               ├─────────⮞│ decoder ├─────⮞───╮
<span class="ln"> 5</span>│          │               │          └─────────┘         │
<span class="ln"> 6</span>└──────────┴───────────────┘                              │
<span class="ln"> 7</span>                                  ╭───────────⮜───────────╯
<span class="ln"> 8</span>                                  │   ┌────────────────────────┐
<span class="ln"> 9</span>                                  │   │  simple filtergraph    │
<span class="ln">10</span>                                  │   ╞════════════════════════╡
<span class="ln">11</span>                                  │   │  ┌───────┐  ┌───────┐  │
<span class="ln">12</span>                                  ╰──⮞├─⮞│ yadif ├─⮞│ scale ├─⮞├╮
<span class="ln">13</span>                                      │  └───────┘  └───────┘  ││
<span class="ln">14</span>                                      └────────────────────────┘│
<span class="ln">15</span>                                                                │
<span class="ln">16</span>                                                                │
<span class="ln">17</span>┌──────────┬───────────────┐ video    ┌─────────┐               │
<span class="ln">18</span>│ muxer    │               │ packets  │  video  │               │
<span class="ln">19</span>╞══════════╡ video stream  │⮜─────────┤ encoder ├───────⮜───────╯
<span class="ln">20</span>│OUTPUT.mp4│               │          │         │
<span class="ln">21</span>│          │               │          └─────────┘
<span class="ln">22</span>└──────────┴───────────────┘
</code></pre></div><h5 id="332-complex-filtergraphs">3.3.2 Complex filtergraphs</h5>
<p>全局的。</p>
<p>Complex filtergraphs are those which cannot be described as simply a linear processing chain applied to one stream. This is the case, for example, when the graph has more than one input and/or output, or when output stream type is different from input. Complex filtergraphs are configured with the <code>-filter_complex</code> option. Note that this option is global, since a complex filtergraph, by its nature, cannot be unambiguously associated with a single stream or file. Each instance of <code>-filter_complex</code> creates a new complex filtergraph, and there can be any number of them.</p>
<p>A trivial example of a complex filtergraph is the <code>overlay</code> filter, which has two video inputs and one video output, containing one video overlaid on top of the other. Its audio counterpart is the <code>amix</code> filter.</p>
<h4 id="34-loopback-decoders">3.4 Loopback decoders</h4>
<p>While decoders are normally associated with demuxer streams, it is also possible to create &ldquo;loopback&rdquo; decoders that decode the output from some encoder and allow it to be fed back to complex filtergraphs. This is done with the <code>-dec</code> directive, which takes as a parameter the index of the output stream that should be decoded. Every such directive creates a new loopback decoder, indexed with successive integers starting at zero. These indices should then be used to refer to loopback decoders（环回解码器） in complex filtergraph link labels, as described in the documentation for<code> -filter_complex</code>.</p>
<p>Decoding AVOptions can be passed to（传递给） loopback decoders by placing them before <code>-dec</code>, analogously（类似的） to input/output options.</p>
<p>TODO 下面这段没看懂</p>
<p>E.g. the following example:</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i INPUT                                        \
<span class="ln">2</span>  -map 0✌️0 -c:v libx264 -crf 45 -f null -            \
<span class="ln">3</span>  -threads 3 -dec 0:0                                  \
<span class="ln">4</span>  -filter_complex &#39;[0:v][dec:0]hstack[stack]&#39;          \
<span class="ln">5</span>  -map &#39;[stack]&#39; -c:v ffv1 OUTPUT
</code></pre></div><p>reads an input video and</p>
<ul>
<li>(line 2) encodes it with <code>libx264</code> at low quality;</li>
<li>(line 3) decodes this encoded stream using 3 threads;</li>
<li>(line 4) places decoded video side by side with the original input video;</li>
<li>(line 5) combined video is then losslessly encoded and written into OUTPUT.</li>
</ul>
<p>Such a transcoding pipeline can be represented with the following diagram:</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln"> 1</span>┌──────────┬───────────────┐
<span class="ln"> 2</span>│ demuxer  │               │   ┌─────────┐            ┌─────────┐    ┌────────────────────┐
<span class="ln"> 3</span>╞══════════╡ video stream  │   │  video  │            │  video  │    │ null muxer         │
<span class="ln"> 4</span>│   INPUT  │               ├──⮞│ decoder ├──┬────────⮞│ encoder ├─┬─⮞│(discards its input)│
<span class="ln"> 5</span>│          │               │   └─────────┘  │         │(libx264)│ │  └────────────────────┘
<span class="ln"> 6</span>└──────────┴───────────────┘                │         └─────────┘ │
<span class="ln"> 7</span>                                 ╭───────⮜──╯   ┌─────────┐       │
<span class="ln"> 8</span>                                 │              │loopback │       │
<span class="ln"> 9</span>                                 │ ╭─────⮜──────┤ decoder ├────⮜──╯
<span class="ln">10</span>                                 │ │            └─────────┘
<span class="ln">11</span>                                 │ │
<span class="ln">12</span>                                 │ │
<span class="ln">13</span>                                 │ │  ┌───────────────────┐
<span class="ln">14</span>                                 │ │  │complex filtergraph│
<span class="ln">15</span>                                 │ │  ╞═══════════════════╡
<span class="ln">16</span>                                 │ │  │  ┌─────────────┐  │
<span class="ln">17</span>                                 ╰─╫─⮞├─⮞│   hstack    ├─⮞├╮
<span class="ln">18</span>                                   ╰─⮞├─⮞│             │  ││
<span class="ln">19</span>                                      │  └─────────────┘  ││
<span class="ln">20</span>                                      └───────────────────┘│
<span class="ln">21</span>                                                           │
<span class="ln">22</span>┌──────────┬───────────────┐  ┌─────────┐                  │
<span class="ln">23</span>│ muxer    │               │  │  video  │                  │
<span class="ln">24</span>╞══════════╡ video stream  │⮜─┤ encoder ├───────⮜──────────╯
<span class="ln">25</span>│  OUTPUT  │               │  │ (ffv1)  │
<span class="ln">26</span>│          │               │  └─────────┘
<span class="ln">27</span>└──────────┴───────────────┘
</code></pre></div><h3 id="4-stream-selection流选择">4 Stream selection（流选择）</h3>
<p><code>ffmpeg</code> provides the <code>-map</code> option for manual control of stream selection in each output file. Users can skip <code>-map</code> and let ffmpeg perform automatic stream selection as described below. The <code>-vn / -an / -sn / -dn</code> options can be used to skip inclusion of video, audio, subtitle and data streams respectively, whether manually mapped or automatically selected, except for those streams which are outputs of complex filtergraphs.</p>
<h4 id="41-description">4.1 Description</h4>
<p>The sub-sections（小节） that follow describe the various rules that are involved in stream selection. The examples that follow next show how these rules are applied in practice.</p>
<p>While every effort is made to accurately reflect the behavior of the program, FFmpeg is under continuous development and the code may have changed since the time of this writing.</p>
<h5 id="411-automatic--stream-selection">4.1.1 Automatic  stream selection</h5>
<p>In the absence of（在没有&hellip;情况下） any map options for a particular output file, ffmpeg inspects the output format to check which type of streams can be included in it, viz. video, audio and/or subtitles. For each acceptable stream type, ffmpeg will pick one stream, when available, from among all the inputs.</p>
<p>It will select that stream based upon the following criteria（标准）:</p>
<ul>
<li>for video, it is the stream with the highest resolution,</li>
<li>for audio, it is the stream with the most channels,</li>
<li>for subtitles, it is the first subtitle stream found but there’s a caveat（警告）. The output format’s default subtitle encoder can be either text-based or image-based, and only a subtitle stream of the same type will be chosen.</li>
</ul>
<p>In the case where several streams of the same type rate equally, the stream with the lowest index is chosen.</p>
<p>Data or attachment streams are not automatically selected and can only be included using <code>-map</code>.</p>
<h5 id="412-manual-stream-selection">4.1.2 Manual stream selection</h5>
<p>When <code>-map</code> is used, only user-mapped streams are included in that output file, with one possible exception for filtergraph outputs described below.</p>
<h5 id="413-complex-filtergraphs">4.1.3 Complex filtergraphs</h5>
<p>If there are any complex filtergraph output streams with unlabeled pads, they will be added to the first output file. This will lead to a fatal error if the stream type is not supported by the output format. In the absence of the map option, the inclusion of these streams leads to the automatic stream selection of their types being skipped. If map options are present, these filtergraph streams are included in addition to（除了..还包括） the mapped streams.</p>
<p>Complex filtergraph output streams with labeled pads must be mapped once and exactly once.</p>
<h5 id="414-stream-handling">4.1.4 Stream handling</h5>
<p>Stream handling（流处理） is independent of stream selection, with an exception for subtitles described below. Stream handling is set via the <code>-codec</code> option addressed to streams within a specific <em>output</em> file. In particular, codec options are applied by ffmpeg after the stream selection process and thus（因此） do not influence the latter. If no <code>-codec</code> option is specified for a stream type, ffmpeg will select the default encoder registered by the output file muxer.</p>
<p>An exception exists for subtitles. If a subtitle encoder is specified for an output file, the first subtitle stream found of any type, text or image, will be included. ffmpeg does not validate if the specified encoder can convert the selected stream or if the converted stream is acceptable within the output format. This applies generally as well: when the user sets an encoder manually, the stream selection process cannot check if the encoded stream can be muxed into the output file. If it cannot, ffmpeg will abort and <em>all</em> output files will fail to be processed.</p>
<h4 id="42-examples">4.2 Examples</h4>
<p>The following examples illustrate the behavior, quirks（怪事） and limitations（局限性） of ffmpeg’s stream selection methods.</p>
<p>They assume the following three input files.</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln"> 1</span>input file &#39;A.avi&#39;
<span class="ln"> 2</span>      stream 0: video 640x360
<span class="ln"> 3</span>      stream 1: audio 2 channels
<span class="ln"> 4</span>
<span class="ln"> 5</span>input file &#39;B.mp4&#39;
<span class="ln"> 6</span>      stream 0: video 1920x1080
<span class="ln"> 7</span>      stream 1: audio 2 channels
<span class="ln"> 8</span>      stream 2: subtitles (text)
<span class="ln"> 9</span>      stream 3: audio 5.1 channels
<span class="ln">10</span>      stream 4: subtitles (text)
<span class="ln">11</span>
<span class="ln">12</span>input file &#39;C.mkv&#39;
<span class="ln">13</span>      stream 0: video 1280x720
<span class="ln">14</span>      stream 1: audio 2 channels
<span class="ln">15</span>      stream 2: subtitles (image)
</code></pre></div><h5 id="example-automatic-stream-selection">Example: automatic stream selection</h5>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i A.avi -i B.mp4 out1.mkv out2.wav -map 1:a -c:a copy out3.mov
</code></pre></div><p>There are three output files specified, and for the first two, no <code>-map</code> options are set, so ffmpeg will select streams for these two files automatically.</p>
<p>out1.mkv is a Matroska container file and accepts video, audio and subtitle streams, so ffmpeg will try to select one of each type.
For video, it will select <code>stream 0</code> from B.mp4, which has the highest resolution among all the input video streams.
For audio, it will select <code>stream 3</code> from B.mp4, since it has the greatest number of channels.
For subtitles, it will select <code>stream 2</code> from B.mp4, which is the first subtitle stream from among A.avi and B.mp4.</p>
<p>out2.wav accepts only audio streams, so only <code>stream 3</code> from B.mp4 is selected.</p>
<p>For out3.mov, since a <code>-map</code> option is set, no automatic stream selection will occur. The <code>-map 1:a</code> option will select all audio streams from the second input B.mp4. No other streams will be included in this output file.</p>
<p>For the first two outputs, all included streams will be transcoded. The encoders chosen will be the default ones registered by each output format, which may not match the codec of the selected input streams.</p>
<p>For the third output, codec option for audio streams has been set to <code>copy</code>, so no decoding-filtering-encoding operations will occur, or <em>can</em> occur. Packets of selected streams shall be conveyed from the input file and muxed within the output file.</p>
<h5 id="example-automatic-subtitles-selection">Example: automatic subtitles selection</h5>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i C.mkv out1.mkv -c:s dvdsub -an out2.mkv
</code></pre></div><p>Although out1.mkv is a Matroska container file which accepts subtitle streams, only a video and audio stream shall be selected. The subtitle stream of C.mkv is image-based and the default subtitle encoder of the Matroska muxer is text-based, so a transcode operation for the subtitles is expected to fail and hence the stream isn’t selected. However, in out2.mkv, a subtitle encoder is specified in the command and so, the subtitle stream is selected, in addition to the video stream. The presence of <code>-an</code> disables audio stream selection for out2.mkv.</p>
<h5 id="example-unlabeled-filtergraph-outputs">Example: unlabeled filtergraph outputs</h5>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i A.avi -i C.mkv -i B.mp4 -filter_complex &#34;overlay&#34; out1.mp4 out2.srt
</code></pre></div><p>A filtergraph is setup here using the <code>-filter_complex</code> option and consists of a single video filter. The <code>overlay</code> filter requires exactly two video inputs, but none are specified, so the first two available video streams are used, those of A.avi and C.mkv. The output pad of the filter has no label and so is sent to the first output file out1.mp4. Due to this, automatic selection of the video stream is skipped, which would have selected the stream in B.mp4. The audio stream with most channels viz（即）. <code>stream 3</code> in B.mp4, is chosen automatically. No subtitle stream is chosen however, since the MP4 format has no default subtitle encoder registered, and the user hasn’t specified a subtitle encoder.</p>
<p>The 2nd output file, out2.srt, only accepts text-based subtitle streams. So, even though the first subtitle stream available belongs to C.mkv, it is image-based and hence skipped. The selected stream, <code>stream 2</code> in B.mp4, is the first text-based subtitle stream.</p>
<h5 id="example-labeled-filtergraph-outputs">Example: labeled filtergraph outputs</h5>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i A.avi -i B.mp4 -i C.mkv -filter_complex &#34;[1:v]hue=s=0[outv];overlay;aresample&#34; \
<span class="ln">2</span>       -map &#39;[outv]&#39; -an        out1.mp4 \
<span class="ln">3</span>                                out2.mkv \
<span class="ln">4</span>       -map &#39;[outv]&#39; -map 1🅰️0 out3.mkv
</code></pre></div><p>The above command will fail, as the output pad labelled <code>[outv]</code> has been mapped twice. None of the output files shall be processed.</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i A.avi -i B.mp4 -i C.mkv -filter_complex &#34;[1:v]hue=s=0[outv];overlay;aresample&#34; \
<span class="ln">2</span>       -an        out1.mp4 \
<span class="ln">3</span>                  out2.mkv \
<span class="ln">4</span>       -map 1🅰️0 out3.mkv
</code></pre></div><p>This command above will also fail as the hue filter output has a label, <code>[outv]</code>, and hasn’t been mapped anywhere.</p>
<p>The command should be modified as follows,</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i A.avi -i B.mp4 -i C.mkv -filter_complex &#34;[1:v]hue=s=0,split=2[outv1][outv2];overlay;aresample&#34; \
<span class="ln">2</span>        -map &#39;[outv1]&#39; -an        out1.mp4 \
<span class="ln">3</span>                                  out2.mkv \
<span class="ln">4</span>        -map &#39;[outv2]&#39; -map 1🅰️0 out3.mkv
</code></pre></div><p>The video stream from B.mp4 is sent to the hue filter, whose output is cloned once using the split filter, and both outputs labelled. Then a copy each is mapped to the first and third output files.</p>
<p>The overlay filter, requiring two video inputs, uses the first two unused video streams. Those are the streams from A.avi and C.mkv. The overlay output isn’t labelled, so it is sent to the first output file out1.mp4, regardless of the presence of the <code>-map</code> option.</p>
<p>The aresample filter is sent the first unused audio stream, that of A.avi. Since this filter output is also unlabelled, it too is mapped to the first output file. The presence of <code>-an</code> only suppresses（抑制） automatic or manual stream selection of audio streams, not outputs sent from filtergraphs. Both these mapped streams shall be ordered before the mapped stream in out1.mp4.</p>
<p>The video, audio and subtitle streams mapped to <code>out2.mkv</code> are entirely determined by automatic stream selection.</p>
<p>out3.mkv consists of the cloned video output from the hue filter and the first audio stream from B.mp4.</p>
<h3 id="5-options选项">5 Options（选项）</h3>
<p>不补了，自己查吧，反正就在那。</p>
<h2 id="使用">使用</h2>
<h3 id="教程">教程</h3>
<ol>
<li>
<p>将input.mp4转换为output.avi格式：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i input.mp4 output.avi
<span class="ln">2</span>ffmpeg -i input.avi output.mp4	
<span class="ln">3</span>   
<span class="ln">4</span>#i：代表和输入文件
</code></pre></div></li>
<li>
<p>设置元数据：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln"> 1</span>#设置元数据键/值对。
<span class="ln"> 2</span>#可以提供可选的元数据指定器来设置流、章节或程序的元数据。有关详细信息，请参阅-map_medata文档。
<span class="ln"> 3</span>#此选项覆盖了使用-map_metadata设置的元数据。也可以使用空值删除元数据。
<span class="ln"> 4</span>   
<span class="ln"> 5</span>ffmpeg -i in.avi -metadata title=&#34;my title&#34; out.flv
<span class="ln"> 6</span>   
<span class="ln"> 7</span>#在输出文件中设置标题
<span class="ln"> 8</span>   
<span class="ln"> 9</span>ffmpeg -i INPUT -metadata:s:a:0 language=eng OUTPUT
<span class="ln">10</span>   
<span class="ln">11</span>#设置第一音频流的语言
</code></pre></div></li>
<li>
<p>将input.mp4的起始时间为00:01:30，时长为30秒钟的部分裁剪出来：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln"> 1</span>ffmpeg -i &#34;input.mp4&#34; -ss 00:01:30 -t 00:00:30 -c copy &#34;output.mp4&#34;
<span class="ln"> 2</span>   
<span class="ln"> 3</span>#ss：当用作输入选项（在-i之前）时，在此输入文件中查找要定位的位置。
<span class="ln"> 4</span>#请注意，在大多数格式中，无法精确查找，因此ffmpeg将查找位置之前最近的查找点。
<span class="ln"> 5</span>#当启用转码和-accurate_seek（默认设置）时，寻道点和位置之间的额外段将被解码并丢弃。
<span class="ln"> 6</span>#在进行流复制或使用-noaccurate_seek时，它将被保留。
<span class="ln"> 7</span>#当用作输出选项时（在输出url之前），会解码但丢弃输入，直到时间戳到达位置。
<span class="ln"> 8</span>   
<span class="ln"> 9</span>#t：当用作输入选项时（在-i之前），限制从输入文件读取数据的持续时间。
<span class="ln">10</span>#当用作输出选项时（在输出url之前），在持续时间达到持续时间后停止写入输出。
</code></pre></div></li>
<li>
<p>将video.mp4和audio.mp3合并成output.mp4：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i &#34;video.mp4&#34; -i audio.mp3 -c:v copy -c:a aac -strict experimental &#34;output.mp4&#34;
<span class="ln">2</span>   
<span class="ln">3</span>#c：为一个或多个流选择编码器（在输出文件之前使用时）或解码器（在输入文件之前使用）。
<span class="ln">4</span>#codec是解码器/编码器或特殊值副本（仅输出）的名称，用于指示流不进行重新编码。
<span class="ln">5</span>#copy就是复制
</code></pre></div></li>
<li>
<p>使用libx264对所有视频流进行编码，并复制所有音频流：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i INPUT -map 0 -c:v libx264 -c:a copy OUTPUT								
</code></pre></div></li>
<li>
<p>复制的所有流，除第二个视频（将使用libx264编码）和第138个音频（将使用libvorbis编码）之外：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i INPUT -map 0 -c copy -c✌️1 libx264 -c🅰️137 libvorbis OUTPUT
</code></pre></div></li>
<li>
<p>将第二个音频流设置为默认流：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i in.mkv -c copy -disposition🅰️1 default out.mkv
</code></pre></div></li>
<li>
<p>使第二字幕流成为默认流并从第一字幕流中删除默认配置：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i in.mkv -c copy -disposition:s:0 0 -disposition:s:1 default out.mkv
<span class="ln">2</span>   
<span class="ln">3</span>#通过设置0来清除
</code></pre></div></li>
<li>
<p>添加嵌入式封面/缩略图：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i in.mp4 -i IMAGE -map 0 -map 1 -c copy -c✌️1 png -disposition✌️1 attached_pic out.mp4
</code></pre></div></li>
<li>
<p>在第一个音频流中添加“原始”并删除“注释”处置标志，而不删除其其他处置标志：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i in.mkv -c copy -disposition🅰️0 +original-comment out.mkv
<span class="ln">2</span>   
<span class="ln">3</span>#要删除“原始”并将“注释”处置标志添加到第一个音频流中，而不删除其其他处置标志
<span class="ln">4</span>ffmpeg -i in.mkv -c copy -disposition🅰️0 -original+comment out.mkv
<span class="ln">5</span>   
<span class="ln">6</span>#在第一个音频流上仅设置“原始”和“注释”处置标志（并删除其其他处置标志）：
<span class="ln">7</span>ffmpeg -i in.mkv -c copy -disposition🅰️0 original+comment out.mkv
</code></pre></div></li>
<li>
<p>从第一个音频流中删除所有处置标志：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i in.mkv -c copy -disposition🅰️0 0 out.mkv
</code></pre></div></li>
<li>
<p>将video.mp4压缩输出为output.mp4，降低码率以减小文件大小：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i video.mp4 -c:v libx264 -crf 23 -c:a aac -b:a 192k output.mp4
<span class="ln">2</span>   
<span class="ln">3</span>#r：作为输入选项，忽略文件中存储的任何时间戳，而是假设帧速率为恒定fps来生成时间戳。
<span class="ln">4</span>#	作为输出选项在编码之前复制或删除帧，以实现恒定的输出帧率fps。视频流拷贝
<span class="ln">5</span>#f：强制输入或输出文件格式。
<span class="ln">6</span>#b:a b代表比特率，a匹配所有的音频流
</code></pre></div></li>
<li>
<p>将输出文件的比特率设置为64kbps：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i input.avi -b:v 64k -bufsize 64k output.mp4
</code></pre></div></li>
<li>
<p>将输出文件的帧率设置为24fps：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln"> 1</span>ffmpeg -i input.avi -r 24 output.mp4
<span class="ln"> 2</span>    
<span class="ln"> 3</span>#r：设置帧率（Hz值、分数或缩写）。
<span class="ln"> 4</span>#作为输入选项，忽略文件中存储的任何时间戳，而是假设帧速率为恒定fps来生成时间戳。
<span class="ln"> 5</span>#这与用于某些输入格式（如image2或v4l2）的-framerate选项不同（在旧版本的FFmpeg中是相同的）。如有疑问，请使用-framerate而不是输入选项-r。
<span class="ln"> 6</span>#作为输出选项：
<span class="ln"> 7</span>#视频编码：
<span class="ln"> 8</span>#在编码之前复制或删除帧，以实现恒定的输出帧率fps。
<span class="ln"> 9</span>#视频流拷贝：
<span class="ln">10</span>#向多路复用器指示fps是流帧率。在这种情况下，没有数据被丢弃或复制。如果fps与数据包时间戳确定的实际流帧率不匹配，则可能会产生无效文件。另请参见sets比特流过滤器。
</code></pre></div></li>
<li>
<p>将输入文件的帧速率（仅对原始格式有效）强制为1 fps，将输出文件的帧速率强制为24 fps：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -r 1 -i input.m2v -r 24 output.mp4
</code></pre></div></li>
<li>
<p>考虑一个名为input.mkv的输入文件，其中有3个基本流，我们从中提取第二个并将其写入文件OUTPUT.mp4：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i INPUT.mkv -map 0:1 -c copy OUTPUT.mp4
<span class="ln">2</span>    
<span class="ln">3</span>#0:1 表示第一个输入文件的第一个2个流。
<span class="ln">4</span>#-c copy：选择拷贝编码器，即不进行解码或编码的流拷贝。
</code></pre></div></li>
<li>
<p>将两个输入文件中的流合并到一个输出中：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i INPUT0.mkv -i INPUT1.aac -map 0:0 -map 1:0 -c copy OUTPUT.mp4
</code></pre></div></li>
<li>
<p>多个流从单个输入拆分为多个输出：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i INPUT.mkv -map 0:0 -c copy OUTPUT0.mp4 -map 0:1 -c copy OUTPUT1.mp4
</code></pre></div></li>
<li>
<p>读取一个包含一个音频和一个视频流的输入文件，对视频进行转码，并将音频复制到一个输出文件中：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i INPUT.mkv -map 0:v -map 0:a -c:v libx264 -c:a copy OUTPUT.mp4
<span class="ln">2</span>    
<span class="ln">3</span>#ffmpeg将对所有音频、视频和字幕流进行转码，除非您为它们指定了-c copy。
</code></pre></div></li>
<li>
<p>流自动选择：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i A.avi -i B.mp4 out1.mkv out2.wav -map 1:a -c:a copy out3.mov
<span class="ln">2</span>    
<span class="ln">3</span>#指定了三个输出文件，对于前两个，没有设置映射选项，因此ffmpeg将自动为这两个文件选择流。
<span class="ln">4</span>#out1.mkv是一个Matroska容器文件，接受视频、音频和字幕流，因此ffmpeg将尝试选择每种类型中的一种。
<span class="ln">5</span>#对于视频，它将从B.mp4中选择流0，B.mp4在所有输入视频流中具有最高的分辨率。
<span class="ln">6</span>#对于音频，它将从B.mp4中选择流3，因为它具有最多的通道。
<span class="ln">7</span>#对于字幕，它将从B.mp4中选择流2，这是A.avi和B.mp4之间的第一个字幕流
<span class="ln">8</span>#out2.wav只接受音频流，因此只选择B.mp4中的流3。因为它具有最多的通道。
<span class="ln">9</span>#对于out3.mov，由于设置了-map选项，因此不会自动选择流。-map 1:a选项将从第二个输入B.mp4中选择所有音频流。此输出文件中不会包含其他流。
</code></pre></div></li>
<li>
<p>流自动选择2（字幕）：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i C.mkv out1.mkv -c:s dvdsub -an out2.mkv
<span class="ln">2</span>    
<span class="ln">3</span>#虽然out1.mkv是一个接受字幕流的Matroska容器文件，但只能选择视频和音频流。C.mkv的字幕流是基于图像的，Matroska多路复用器的默认字幕编码器是基于文本的，因此字幕的转码操作预计会失败，因此不会选择该流。
<span class="ln">4</span>#然而，在out2.mkv中，命令中指定了字幕编码器，因此除了视频流外，还选择了字幕流。
<span class="ln">5</span>#-an的存在将禁用out2.mkv的音频流选择。
</code></pre></div></li>
<li>
<p>流自动选择3（没有标签的复杂滤镜图的输出）：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i A.avi -i C.mkv -i B.mp4 -filter_complex &#34;overlay&#34; out1.mp4 out2.srt
<span class="ln">2</span>    
<span class="ln">3</span>#这里使用-filter_complex选项设置了一个过滤器图，它由一个视频过滤器组成。叠加滤镜图需要两个视频输入，但没有指定，因此使用前两个可用的视频流，即A.avi和C.mkv。过滤器的输出焊盘没有标签，因此被发送到第一个输出文件out1.mp4。
<span class="ln">4</span>#因此，跳过视频流的自动选择，这将选择B.mp4中的流。自动选择具有大多数channel的音频流，即B.mp4中的流3。但是，由于MP4格式没有注册默认字幕编码器，用户也没有指定字幕编码器，因此没有选择字幕流。
</code></pre></div></li>
<li>
<p>流自动选择4（有标签的复杂滤镜图的输出）：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln"> 1</span>ffmpeg -i A.avi -i B.mp4 -i C.mkv -filter_complex &#34;[1:v]hue=s=0[outv];overlay;aresample&#34; \
<span class="ln"> 2</span>       -map &#39;[outv]&#39; -an        out1.mp4 \
<span class="ln"> 3</span>                                out2.mkv \
<span class="ln"> 4</span>       -map &#39;[outv]&#39; -map 1🅰️0 out3.mkv
<span class="ln"> 5</span>           
<span class="ln"> 6</span>#上述命令将失败，因为标记为[outv]的输出焊盘已被映射两次。不得处理任何输出文件。
<span class="ln"> 7</span>    
<span class="ln"> 8</span>ffmpeg -i A.avi -i B.mp4 -i C.mkv -filter_complex &#34;[1:v]hue=s=0[outv];overlay;aresample&#34; \
<span class="ln"> 9</span>       -an        out1.mp4 \
<span class="ln">10</span>                  out2.mkv \
<span class="ln">11</span>       -map 1🅰️0 out3.mkv
<span class="ln">12</span>    
<span class="ln">13</span>#上述命令也将失败，因为色调过滤器输出有一个标签[outv]，并且没有映射到任何地方。
<span class="ln">14</span>    
<span class="ln">15</span>ffmpeg -i A.avi -i B.mp4 -i C.mkv -filter_complex &#34;[1:v]hue=s=0,split=2[outv1][outv2];overlay;aresample&#34; \
<span class="ln">16</span>        -map &#39;[outv1]&#39; -an        out1.mp4 \
<span class="ln">17</span>                                  out2.mkv \
<span class="ln">18</span>        -map &#39;[outv2]&#39; -map 1🅰️0 out3.mkv
<span class="ln">19</span>    
<span class="ln">20</span>#来自B.mp4的视频流被发送到色调过滤器，使用分割过滤器（split）克隆一次色调过滤器的输出，并标记两个输出。然后，每个副本都被映射到第一个和第三个输出文件。
<span class="ln">21</span>#叠加滤镜图（overlay）需要两个视频输入，使用前两个未使用的视频流。这些是来自A.avi和C.mkv的流。
<span class="ln">22</span>#覆盖overlay的输出没有标记（label），因此无论是否存在-map选项，它都会被发送到第一个输出文件out1.mp4。
<span class="ln">23</span>#aresample过滤器被发送第一个未使用的音频流，即A.avi的音频流。由于此过滤器输出也未标记，因此它也被映射到第一个输出文件out1.mp4
<span class="ln">24</span>#-an的存在只会抑制音频流的自动或手动流选择，而不会抑制从滤镜图图发送的输出。这两个映射流应在out1.mp4中的映射流之前排序。
<span class="ln">25</span>#映射到out2.mkv的视频、音频和字幕流完全由自动流选择决定。
<span class="ln">26</span>#out3.mkv由色调滤镜图的克隆视频输出和B.mp4的第一个音频流组成。
<span class="ln">27</span>#1🅰️0 B.mp4的第一个音频流
</code></pre></div></li>
<li>
<p>从文件中加载命令：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i INPUT -/filter:v filter.script OUTPUT
<span class="ln">2</span>    
<span class="ln">3</span>#接受参数的选项支持一种特殊语法，其中命令行上给出的参数被解释为加载实际参数值的文件的路径。要使用此功能，请在选项名称之前（前导破折号之后）添加一个正斜杠“/”。
<span class="ln">4</span>#将从名为filter.script的文件中加载过滤器图描述
</code></pre></div></li>
<li>
<p>将第一个输入文件中的所有流映射到输出：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i INPUT -map 0 output
</code></pre></div></li>
<li>
<p>将input中的第二个输入流映射到out.wav中的（单个）输出流：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i INPUT -map 0:1 out.wav
</code></pre></div></li>
<li>
<p>从输入文件中选择所有视频和第三个音频流：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i INPUT -map 0:v -map 0🅰️2 OUTPUT
</code></pre></div></li>
<li>
<p>映射除第二个音频之外的所有流，请使用负映射：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i INPUT -map 0 -map -0🅰️1 OUTPUT
</code></pre></div></li>
<li>
<p>映射来自第一个输入的视频和音频流，并使用尾随？，这样如果第一输入中不存在音频流，则忽略音频映射：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i INPUT -map 0:v -map 0:a? OUTPUT
</code></pre></div></li>
<li>
<p>选择英语音频流：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i INPUT -map 0ⓜ️language:eng OUTPUT
</code></pre></div></li>
<li>
<p>将输出mpegts文件的流0 PID设置为33，流1 PID设置为36：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i inurl -streamid 0:33 -streamid 1:36 out.ts
</code></pre></div></li>
<li>
<p>将h264_mp4toannexb比特流过滤器（将MP4封装的H.264流转换为附件B）应用于输入视频流:</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -bsf:v h264_mp4toannexb -i h264.mp4 -c:v copy -an out.h264
</code></pre></div></li>
<li>
<p>将mov2textsub比特流过滤器（从MOV字幕中提取文本）应用于输出字幕流:</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i file.mov -an -vn -bsf:s mov2textsub -c:s copy -f rawvideo sub.txt
</code></pre></div></li>
<li>
<p>环回解码器+复杂滤波图应用1：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln"> 1</span>ffmpeg -i INPUT                                        \
<span class="ln"> 2</span>  -map 0✌️0 -c:v libx264 -crf 45 -f null -            \
<span class="ln"> 3</span>  -threads 3 -dec 0:0                                  \
<span class="ln"> 4</span>  -filter_complex &#39;[0:v][dec:0]hstack[stack]&#39;          \
<span class="ln"> 5</span>  -map &#39;[stack]&#39; -c:v ffv1 OUTPUT
<span class="ln"> 6</span>      
<span class="ln"> 7</span># 0✌️0 第一个输入的第一个视频流， 最后面这个0是view_specifier（视图说明符）
<span class="ln"> 8</span>#-dec：对某些编码器的输出进行解码，并将其反馈给复杂的滤镜图图。这是通过-dec指令完成的，该指令将应解码的输出流的索引作为参数
<span class="ln"> 9</span>#-filter_complex：定义一个复杂的滤波图
<span class="ln">10</span>#[file_index:stream_specifier]：连接输入流，如果stream_specifier匹配多个流，则将使用第一个流。对于多视图视频，流说明符后面可能跟有视图说明符
<span class="ln">11</span>#[dec:dec_idx]：环回解码器，其中dec_idx是要连接到给定输入的环回解码器的索引。对于多视图视频，解码器索引后面可能跟有视图说明符
<span class="ln">12</span>#[stack]：是输出标签。
</code></pre></div></li>
<li>
<p>环回解码器+复杂滤波图应用2：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln"> 1</span>ffmpeg -i input.mkv \
<span class="ln"> 2</span>  -filter_complex &#39;[0:v]scale=size=hd1080,split=outputs=2[for_enc][orig_scaled]&#39; \
<span class="ln"> 3</span>  -c:v libx264 -map &#39;[for_enc]&#39; output.mkv \
<span class="ln"> 4</span>  -dec 0:0 \
<span class="ln"> 5</span>  -filter_complex &#39;[dec:0][orig_scaled]hstack[stacked]&#39; \
<span class="ln"> 6</span>  -map &#39;[stacked]&#39; -c:v ffv1 comparison.mkv
<span class="ln"> 7</span>      
<span class="ln"> 8</span># []包围的名称基本都是标签。
<span class="ln"> 9</span>#（第2行）使用具有一个输入和两个输出的复杂滤镜图图将视频缩放到1920x1080，并将结果复制到两个输出；
<span class="ln">10</span>#（第3行）用libx264对一个缩放输出进行编码，并将结果写入output.mkv；
<span class="ln">11</span>#（第4行）用环回解码器对该编码流进行解码；
<span class="ln">12</span>#（第5行）将环回解码器的输出（即libx264编码视频）与缩放的原始输入并排放置（hstack）；
<span class="ln">13</span>#（第6行）然后对组合视频进行无损编码（ffv1）并写入comparison.mkv。
</code></pre></div></li>
<li>
<p>将图像叠加在视频上：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i video.mkv -i image.png -filter_complex &#39;[0:v][1:v]overlay[out]&#39; -map
<span class="ln">2</span>&#39;[out]&#39; out.mkv
<span class="ln">3</span>    
<span class="ln">4</span>#假设每个输入文件中只有一个视频流，我们可以省略输入标签
<span class="ln">5</span>ffmpeg -i video.mkv -i image.png -filter_complex &#39;overlay[out]&#39; -map
<span class="ln">6</span>&#39;[out]&#39; out.mkv
<span class="ln">7</span>    
<span class="ln">8</span>#此外，我们可以省略输出标签，过滤器图中的单个输出将自动添加到输出文件中
<span class="ln">9</span>ffmpeg -i video.mkv -i image.png -filter_complex &#39;overlay&#39; out.mkv
</code></pre></div></li>
<li>
<p>以MPEG-TS格式存储的DVB-T记录上硬编码字幕，将字幕延迟1秒：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i input.ts -filter_complex \
<span class="ln">2</span>  &#39;[#0x2ef] setpts=PTS+1/TB [sub] ; [#0x2d0] [sub] overlay&#39; \
<span class="ln">3</span>  -sn -map &#39;#0x2dc&#39; output.mkv
<span class="ln">4</span>      
<span class="ln">5</span>#0x2d0、0x2dc和0x2ef分别是视频、音频和字幕流的MPEG-TS PID；0:0、0:3和0:7也会奏效
<span class="ln">6</span>#作为一个特殊的例外，您可以使用位图字幕流作为输入：它将被转换为与文件中最大视频大小相同的视频，如果没有视频，则转换为720x576。
<span class="ln">7</span>#-sn：作为输入选项，阻止文件的所有字幕流被过滤或自动选择或映射到任何输出。请参阅-discard选项以单独禁用流。
<span class="ln">8</span>#作为输出选项，禁用字幕录制，即自动选择或映射任何字幕流。有关完全手动控制，请参阅-map选项。
</code></pre></div></li>
<li>
<p>使用lavfi色源生成5秒的纯红色视频：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -filter_complex &#39;color=c=red&#39; -t 5 out.mkv
</code></pre></div></li>
<li>
<p>将ID3v2.3标头而不是默认的ID3v2.4写入MP3文件，请使用MP3多路复用器的ID3v2_version私有选项：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i input.flac -id3v2_version 3 out.mp3
</code></pre></div></li>
<li>
<p>添加附件：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i INPUT -attach DejaVuSans.ttf -metadata:s:2 mimetype=application/x-truetype-font out.mkv
</code></pre></div></li>
<li>
<p>提取附件：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -dump_attachment:t:0 out.ttf -i INPUT
<span class="ln">2</span>#提取名为“out.ttf”的文件的第一个附件
<span class="ln">3</span>    
<span class="ln">4</span>    
<span class="ln">5</span>ffmpeg -dump_attachment:t &#34;&#34; -i INPUT
<span class="ln">6</span>#提取由文件名标记确定的文件的所有附件
</code></pre></div></li>
<li>
<p>显示输入设备的自动检测源：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -sources pulse,server=192.168.0.4
</code></pre></div></li>
<li>
<p>显示输出设备的自动检测接收器：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -sinks pulse,server=192.168.0.4
</code></pre></div></li>
<li>
<p>启用重复日志输出：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -loglevel repeat+level+verbose -i input output
<span class="ln">2</span>    
<span class="ln">3</span>#允许重复日志输出而不影响当前级别前缀标志或日志级别状态：
<span class="ln">4</span>ffmpeg [...] -loglevel +repeat
</code></pre></div></li>
<li>
<p>使用32的日志级别（日志级别信息的别名）将报告输出到名为ffreport.log的文件：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>FFREPORT=file=ffreport.log:level=32 ffmpeg -i input output
</code></pre></div></li>
<li>
<p>允许设置和清除cpu标志。此选项用于测试：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -cpuflags -sse+mmx ...
<span class="ln">2</span>ffmpeg -cpuflags mmx ...
<span class="ln">3</span>ffmpeg -cpuflags 0 ...
</code></pre></div></li>
<li>
<p>覆盖CPU计数检测。此选项用于测试：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -cpucount 2
</code></pre></div></li>
<li>
<p>将进度信息记录到stdout：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -progress pipe:1 -i in.mkv out.mkv
</code></pre></div></li>
</ol>
<h3 id="官方示例">官方示例</h3>
<ol>
<li>
<p>指定了输入格式和设备，那么ffmpeg可以直接抓取视频和音频：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -f oss -i /dev/dsp -f video4linux2 -i /dev/video0 /tmp/out.mpg
<span class="ln">2</span>   
<span class="ln">3</span>#使用ALSA音频源（单声道输入，卡id 1）而不是OSS：
<span class="ln">4</span>ffmpeg -f alsa -ac 1 -i hw:1 -f video4linux2 -i /dev/video0 /tmp/out.mpg
</code></pre></div></li>
<li>
<p>通过ffmpeg抓取X11显示器：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -f x11grab -video_size cif -framerate 25 -i :0.0 /tmp/out.mpg
<span class="ln">2</span>#使用ffmpeg通过0.0抓取X11显示器。X11服务器的屏幕号与display环境变量相同。
<span class="ln">3</span>   
<span class="ln">4</span>   
<span class="ln">5</span>ffmpeg -f x11grab -video_size cif -framerate 25 -i :0.0+10,20 /tmp/out.mpg
<span class="ln">6</span>#0.0是X11服务器的display.screen编号，与display环境变量相同。10是抓取的x偏移，20是抓取的y偏移。
</code></pre></div></li>
<li>
<p>可以使用YUV文件作为输入：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i /tmp/test%d.Y /tmp/out.mpg
<span class="ln">2</span>   
<span class="ln">3</span>#会使用文件：
<span class="ln">4</span>#/tmp/test0.Y, /tmp/test0.U, /tmp/test0.V,
<span class="ln">5</span>#/tmp/test1.Y, /tmp/test1.U, /tmp/test1.V, etc...
<span class="ln">6</span>#Y文件的分辨率是U和V文件的两倍。它们是原始文件，没有标题。它们可以由所有像样的视频解码器生成。如果ffmpeg无法猜测，则必须使用-s选项指定图像的大小。
</code></pre></div></li>
<li>
<p>从原始YUV420P文件输入</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i /tmp/test.yuv /tmp/out.avi
<span class="ln">2</span>   
<span class="ln">3</span>#test.yuv是一个包含原始yuv平面数据的文件。每一帧由Y平面、U平面和V平面组成，具有半垂直和水平分辨率。
</code></pre></div></li>
<li>
<p>可以输出到原始YUV420P文件：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i mydivx.avi hugefile.yuv
</code></pre></div></li>
<li>
<p>可以设置多个输入文件和输出文件：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i /tmp/a.wav -s 640x480 -i /tmp/a.yuv /tmp/a.mpg
<span class="ln">2</span>#将音频文件a.wav和原始YUV视频文件a.YUV转换为MPEG文件a.mpg。
</code></pre></div></li>
<li>
<p>同时进行音频和视频转换：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i /tmp/a.wav -ar 22050 /tmp/a.mp2
<span class="ln">2</span>#以22050 Hz的采样率将.wav转换为MPEG音频
</code></pre></div></li>
<li>
<p>同时编码为多种格式，并定义从输入流到输出流的映射：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i /tmp/a.wav -map 0:a -b:a 64k /tmp/a.mp2 -map 0:a -b:a 128k /tmp/b.mp2
<span class="ln">2</span>#将.wav转换为64 kbits的a.mp2和128 kbits的b.mp2。
<span class="ln">3</span>#-map file:index按照输出流的定义顺序指定每个输出流使用哪个输入流。
</code></pre></div></li>
<li>
<p>对解密的VOB进行转码：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i snatch_1.vob -f avi -c:v mpeg4 -b:v 800k -g 300 -bf 2 -c:a libmp3lame -b:a 128k snatch.avi
<span class="ln">2</span>   
<span class="ln">3</span>#这是一个典型的DVD翻录示例；输入是VOB文件、输出是具有MPEG-4视频和MP3音频的AVI文件。
<span class="ln">4</span>#请注意，在此命令中，我们使用B帧，因此MPEG-4流与DivX5兼容，GOP大小为300，这意味着对于29.97fps的输入视频，每10秒有一个帧内帧。
<span class="ln">5</span>#此外，音频流是MP3编码的，因此您需要通过传递--enable-libmp3lame进行配置来启用LAME支持。该映射对于DVD转码以获得所需的音频语言特别有用。
</code></pre></div></li>
<li>
<p>从视频中提取图像：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i foo.avi -r 1 -s WxH -f image2 foo-%03d.jpeg
<span class="ln">2</span>    
<span class="ln">3</span>#这将从视频中每秒提取一个视频帧，并将其输出到名为foo-001.jpeg、foo-002.jpeg等的文件中。图像将被重新缩放以适应新的WxH值。
<span class="ln">4</span>#如果只想提取有限数量的帧，可以将上述命令与-frames:v或-t选项结合使用，或与-ss结合使用，从某个时间点开始提取。
</code></pre></div></li>
<li>
<p>从许多图像创建视频：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -f image2 -framerate 12 -i foo-%03d.jpeg -s WxH foo.avi
<span class="ln">2</span>    
<span class="ln">3</span>#语法foo-%03d.jpeg指定使用由三个填充零的数字组成的十进制数来表示序列号。它与C printf函数支持的语法相同，但只有接受普通整数的格式才合适。
<span class="ln">4</span>#在导入图像序列时，-i还支持通过选择image2特定的-pattern_type glob选项在内部扩展类似shell的通配符模式（globbing）。
<span class="ln">5</span>    
<span class="ln">6</span>ffmpeg -f image2 -pattern_type glob -framerate 12 -i &#39;foo-*.jpeg&#39; -s WxH foo.avi
<span class="ln">7</span>#为了从与glob模式foo-*.jpeg匹配的文件名创建视频
</code></pre></div></li>
<li>
<p>在输出中放入许多相同类型的流：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i test1.avi -i test2.avi -map 1:1 -map 1:0 -map 0:1 -map 0:0 -c copy -y test12.nut
<span class="ln">2</span>    
<span class="ln">3</span>#生成的输出文件test12.nut将以相反的顺序包含输入文件的前四个流。
</code></pre></div></li>
<li>
<p>强制CBR视频输出：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i myfile.avi -b 4000k -minrate 4000k -maxrate 4000k -bufsize 1835k out.m2v
</code></pre></div></li>
<li>
<p>lmin、lmax、mblmin和mblmax这四个选项使用“lambda”单位，但您可以使用QP2LAMBDA常数轻松地从“q”单位转换：</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg -i src.ext -lmax 21*QP2LAMBDA dst.ext
</code></pre></div></li>
</ol>
<h2 id="场景">场景</h2>
<p>我目前的需求很简单，就是转换下格式及编码，还有推流。</p>
<h3 id="推流">推流</h3>
<ol>
<li>
<p>推送rtp</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg - re - i cw.ts - vcodec copy - acodec copy - f rtp_mpegts rtp://238.123.46.66:8001
<span class="ln">2</span>   
<span class="ln">3</span>ffmpeg -re -i chunwan.h264 -vcodec copy -f rtp rtp://233.233.233.223:6666&gt;test.sdp  
<span class="ln">4</span>#发送H.264裸流“chunwan.h264”至地址rtp://233.233.233.223:6666
<span class="ln">5</span>#最右边的“&gt;test.sdp”用于将ffmpeg的输出信息存储下来形成一个sdp文件。该文件用于RTP的接收。当不加“&gt;test.sdp”的时候，ffmpeg会直接把sdp信息输出到控制台。将该信息复制出来保存成一个后缀是.sdp文本文件，也是可以用来接收该RTP流的。加上“&gt;test.sdp”后，可以直接把这些sdp信息保存成文本。
</code></pre></div></li>
<li>
<p>推送UDP</p>
<div class="highlight"><pre class="chroma"><code class="language-fallback" data-lang="fallback"><span class="ln">1</span>ffmpeg - re - i cw.ts - vcodec copy - acodec copy - f mpegts udp://238.123.46.66:8001 	
<span class="ln">2</span>   
<span class="ln">3</span>ffmpeg -re -i chunwan.h264 -vcodec copy -f h264 udp://233.233.233.223:6666  
<span class="ln">4</span>#发送H.264裸流“chunwan.h264”至地址udp://233.233.233.223:6666
<span class="ln">5</span>#-re一定要加，代表按照帧率发送，否则ffmpeg会一股脑地按最高的效率发送数据。
<span class="ln">6</span>#-vcodec copy要加，否则ffmpeg会重新编码输入的H.264裸流。
<span class="ln">7</span>   
<span class="ln">8</span>ffmpeg -re -i chunwan.h264 -vcodec mpeg2video -f mpeg2video udp://233.233.233.223:6666  
<span class="ln">9</span>#读取本地摄像头的数据，编码为MPEG2，发送至地址udp://233.233.233.223:6666。	
</code></pre></div></li>
</ol></div><hr /><div class="post-navs d-flex mb-3 justify-content-between">
  <div class="post-nav w-50"><div class="prev-post btn btn-sm">
      <a href="/posts/tech/media-pcmu/">pcmu编码学习
</a>
    </div></div>
  <div class="post-nav flex-row-reverse"><div class="next-post btn btn-sm">
      <a href="/posts/other/physics-computer/">计算机和物理的一点感悟
</a>
    </div></div>
</div><section class="related-posts">
    <h3>相关文章</h3>
    <ul class="related-posts"><li><a href="/posts/tech/media-sox/">Sox软件基本使用
</a></li><li><a href="/posts/tech/media-pcmu/">pcmu编码学习
</a></li><li><a href="/posts/tech/media-automake/">automake工具使用
</a></li><li><a href="/posts/tech/media-datastructure/">《数据结构与算法分析: C语言描述》
</a></li><li><a href="/posts/tech/media-rtp/">RTP协议学习
</a></li></ul>
  </section></article>




<div id="vcomments" class="post-comments surface row">
</div>
    <script>
        new Valine({
            el: '#vcomments',
            appId: '18xpdRPZMKmyTjmjtMIK8zyB-gzGzoHsz',
            appKey: 'haH3Ysz9ic7RFcoqbIvPDh8H',
            avatar:'retro',
            visitor:true,
            placeholder:'有什么想说的吗？'

        });

        var count = 0;
        var domTimer = setInterval(function () {
            if (++count > 50) clearInterval(domTimer);
            if (document.querySelector('#veditor')) {
                clearInterval(domTimer);
                var cdraw = new CaveDraw({
                    element: "#veditor",
                    readOnlyMode: false, 
                    afterUpdateEditor: ()=>{ 
                        document.querySelector('#veditor').focus();
                        document.querySelector('#veditor').blur();
                    },
                    controls: ['brush', 'eraser', 'bucket', 'clear', 'undo', 'redo', 'save']
                });
            }
        }, 200);
    </script></div>
</div><aside class="col-lg-4 sidebar d-flex">
  <div class="container"><section class="profile surface row">
  <div class="col-xl-6 d-flex align-items-center justify-content-center">
    <img class="profile-avatar img-fluid" src="/images/profile2.jpg" alt="理想奈" loading="lazy">
  </div>
  <div class="col-xl-6">
    <h5 class="profile-name my-2">理想奈</h5><div class="profile-bio mb-2">所愿所爱所喜所恨所感，即行之所往。 既是原因，也是目的。</div>
    
  </div>
</section><section class="recent-posts row surface">
  <h4>最近文章</h4>
  <ul><li><a href="/posts/tech/media-msml/">MSML语言学习
</a></li><li><a href="/posts/tech/media-netpackage-observe/">观察SIP， SDP，RTP包及MSML
</a></li><li><a href="/posts/tech/media-sipp/">SIPP工具学习
</a></li><li><a href="/posts/tech/media-sip/">SIP协议学习
</a></li><li><a href="/posts/tech/media-rebar2/">rebar2工具学习
</a></li><li><a href="/posts/tech/media-erlang/">《Erlang程序设计》
</a></li><li><a href="/posts/other/2024/">2024年终总结和来年展望
</a></li><li><a href="/posts/math/estimate/">量化交易系统设想
</a></li><li><a href="/posts/math/beginner/">量化交易初学
</a></li><li><a href="/posts/tech/media-computer-systems/">《深入理解计算机系统》
</a></li><li><a href="/posts/other/physics-computer/">计算机和物理的一点感悟
</a></li><li><a href="/posts/tech/media-ffmpeg/">FFmpeg软件学习
</a></li><li><a href="/posts/tech/media-pcmu/">pcmu编码学习
</a></li></ul>
</section><section class="taxonomy-categories row surface">
      <h4>
        <a href="/categories">分类</a>
      </h4>
      <div><a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/" class="post-taxonomy rounded btn btn-sm me-2 mb-2" title="计算机">
          计算机 <span class="badge rounded-pill">41</span>
        </a><a href="/categories/%E4%BA%8C%E6%AC%A1%E5%85%83/" class="post-taxonomy rounded btn btn-sm me-2 mb-2" title="二次元">
          二次元 <span class="badge rounded-pill">24</span>
        </a><a href="/categories/%E6%99%AE%E9%80%9A%E7%B1%BB/" class="post-taxonomy rounded btn btn-sm me-2 mb-2" title="普通类">
          普通类 <span class="badge rounded-pill">9</span>
        </a><a href="/categories/%E6%96%87%E5%AD%97%E7%B1%BB/" class="post-taxonomy rounded btn btn-sm me-2 mb-2" title="文字类">
          文字类 <span class="badge rounded-pill">6</span>
        </a><a href="/categories/%E6%95%B0%E5%AD%A6%E7%B1%BB/" class="post-taxonomy rounded btn btn-sm me-2 mb-2" title="数学类">
          数学类 <span class="badge rounded-pill">4</span>
        </a></div>
    </section><section class="taxonomy-series row surface">
      <h4>
        <a href="/series">专栏</a>
      </h4>
      <div><a href="/series/%E5%AA%92%E4%BD%93%E5%BC%80%E5%8F%91/" class="post-taxonomy rounded btn btn-sm me-2 mb-2" title="媒体开发">
          媒体开发 <span class="badge rounded-pill">26</span>
        </a><a href="/series/%E5%8A%A8%E6%BC%AB%E6%AD%8C%E6%9B%B2/" class="post-taxonomy rounded btn btn-sm me-2 mb-2" title="动漫歌曲">
          动漫歌曲 <span class="badge rounded-pill">21</span>
        </a><a href="/series/galgame/" class="post-taxonomy rounded btn btn-sm me-2 mb-2" title="Galgame">
          Galgame <span class="badge rounded-pill">10</span>
        </a><a href="/series/java/" class="post-taxonomy rounded btn btn-sm me-2 mb-2" title="Java">
          Java <span class="badge rounded-pill">10</span>
        </a><a href="/series/%E9%87%8F%E5%8C%96%E4%BA%A4%E6%98%93/" class="post-taxonomy rounded btn btn-sm me-2 mb-2" title="量化交易">
          量化交易 <span class="badge rounded-pill">2</span>
        </a><a href="/series/%E9%9A%8F%E6%84%8F%E6%80%9D%E8%80%83/" class="post-taxonomy rounded btn btn-sm me-2 mb-2" title="随意思考">
          随意思考 <span class="badge rounded-pill">2</span>
        </a></div>
    </section></div>
</aside>
</div>
    </main><footer class="footer mt-auto py-3 text-center container"><nav class="social-links nav my-2 justify-content-center"></nav>
<div class="copyright mb-2">
  Copyright © 2021-2025 Unaybaryl. All Rights Reserved.
</div>
</footer>
<a id="btnScrollToTop" class="btn-scroll-to-top">
  <i class="fas fa-fw fa-chevron-circle-up fa-2x"></i>
</a>



              
            </body>
</html>
